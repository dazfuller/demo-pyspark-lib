# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- main

variables:
- group: databricks-deployment
- name: python-version
  value: '3.7'

stages:
- stage: Build
  jobs:
  - job: sparklib
    displayName: 'Build demo library'
    pool:
      vmImage: 'ubuntu-latest'

    steps:
      - checkout: self
        persistCredentials: true
      
      - task: PowerShell@2
        inputs:
          targetType: 'inline'
          script: |
            $branch = "$(Build.SourceBranch)" -replace "refs/heads/",""
            git checkout "$branch"
            git config --global user.email "build@dev.azure.com"
            git config --global user.name "Azure DevOps"
          pwsh: true
        condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
        displayName: 'Re-attach git to branch'
      
      - task: UsePythonVersion@0
        inputs:
          versionSpec: $(python-version)
          addToPath: true
          architecture: 'x64'
        displayName: 'Set up Python 3'

      - task: PowerShell@2
        inputs:
          targetType: 'inline'
          pwsh: true
          script: |
            python3 -m pip install --upgrade pip
            python3 -m pip install -r requirements.txt
        displayName: 'Install dependencies'
      
      - task: PowerShell@2
        inputs:
          targetType: 'inline'
          pwsh: true
          script: |
            python3 -m coverage run --branch -m xmlrunner -o test-results discover -v -s ./tests -p test_*.py
            python3 -m coverage xml
            python3 -m coverage html
        displayName: 'Run tests and produce code coverage'
      
      - task: PublishTestResults@2
        inputs:
          testResultsFormat: 'JUnit'
          testResultsFiles: 'test-results/TEST-*.xml'
          mergeTestResults: true
          failTaskOnFailedTests: true
          testRunTitle: 'Test results for build id $(Build.BuildId)'
        displayName: 'Publish unit tests'
      
      - task: PublishCodeCoverageResults@1
        inputs:
          codeCoverageTool: 'Cobertura'
          summaryFileLocation: 'coverage.xml'
          reportDirectory: 'htmlcov'
        displayName: 'Publish code coverage results'

      - task: PowerShell@2
        inputs:
          targetType: inline
          pwsh: true
          script: |
            ./set-version -IsDevRelease -BuildId $(Build.BuildId)
            python setup.py bdist_wheel
        condition: and(succeeded(), ne(variables['Build.SourceBranch'], 'refs/heads/main'))
        displayName: 'Build the test wheel file'

      - task: PowerShell@2
        inputs:
          targetType: inline
          pwsh: true
          script: |
            ./set-version
            python setup.py bdist_wheel
        condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
        displayName: 'Build the production wheel file'

      - task: PowerShell@2
        inputs:
          targetType: inline
          pwsh: true
          script: |
            $versionMatch = Get-Content ./setup.py | Select-String -Pattern "version=`"(.+)`""
            $version = $versionMatch.Matches.Groups[1].Value

            git add .
            git commit -m "update to version $version from pipeline [skip ci]"
            git tag v$version
            git push
        condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
        displayName: 'Commit version information back'
      
      - task: PublishPipelineArtifact@1
        inputs:
          targetPath: 'dist'
          artifactName: LibWheel
        displayName: 'Publish artifact to pipeline'

- stage: DeployTest
  displayName: 'Deploy to test'
  dependsOn: Build
  condition: succeeded()
  jobs:
  - deployment: Deployment
    displayName: 'Deploy library to test'
    environment: 'Test-Databricks'
    pool:
      vmImage: 'ubuntu-latest'
    strategy:
      runOnce:
        deploy:
          steps:
            - task: DownloadPipelineArtifact@2
              inputs:
                artifactName: LibWheel
                patterns: '**/*.whl'
                path: $(Build.SourcesDirectory)/dist
              displayName: 'Download artifact from pipeline'
            
            - task: UsePythonVersion@0
              inputs:
                versionSpec: $(python-version)
                addToPath: true
                architecture: 'x64'
              displayName: 'Set up Python 3'
            
            - task: PowerShell@2
              inputs:
                targetType: 'inline'
                pwsh: true
                script: |
                  python3 -m pip install databricks-cli
              displayName: 'Install Databricks CLI'
            
            - task: PowerShell@2
              inputs:
                targetType: 'inline'
                pwsh: true
                script: |
                  $WheelFile = Get-ChildItem -Path ./dist -Filter *.whl | Select-Object -First 1
                  databricks fs mkdirs dbfs:/FileStore/libraries
                  databricks fs cp $WheelFile.FullName dbfs:/FileStore/libraries
              env:
                DATABRICKS_HOST: $(test-databricks-host)
                DATABRICKS_TOKEN: $(test-databricks-pat)
              displayName: 'Publish wheel file to test workspace'
  
- stage: DeployProd
  displayName: 'Deploy to production'
  dependsOn: DeployTest
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
  jobs:
  - deployment: Deployment
    displayName: 'Deploy library to production'
    environment: 'Production-Databricks'
    pool:
      vmImage: 'ubuntu-latest'
    strategy:
      runOnce:
        deploy:
          steps:
            - task: DownloadPipelineArtifact@2
              inputs:
                artifactName: LibWheel
                patterns: '**/*.whl'
                path: $(Build.SourcesDirectory)/dist
              displayName: 'Download artifact from pipeline'
            
            - task: UsePythonVersion@0
              inputs:
                versionSpec: $(python-version)
                addToPath: true
                architecture: 'x64'
              displayName: 'Set up Python 3'
            
            - task: PowerShell@2
              inputs:
                targetType: 'inline'
                pwsh: true
                script: |
                  python3 -m pip install databricks-cli
              displayName: 'Install Databricks CLI'
            
            - task: PowerShell@2
              inputs:
                targetType: 'inline'
                pwsh: true
                script: |
                  $WheelFile = Get-ChildItem -Path ./dist -Filter *.whl | Select-Object -First 1
                  databricks fs mkdirs dbfs:/FileStore/libraries
                  databricks fs cp $WheelFile.FullName dbfs:/FileStore/libraries
              env:
                DATABRICKS_HOST: $(test-databricks-host)
                DATABRICKS_TOKEN: $(test-databricks-pat)
              displayName: 'Publish wheel file to production workspace'
